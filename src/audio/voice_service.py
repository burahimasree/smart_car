#!/usr/bin/env python3
"""Production Voice Service: Wakeword + STT with interrupt capability.

TESTED AND WORKING:
- 10/10 wakeword detection rate with scipy resampling (48kHz ‚Üí 16kHz)
- Silence detection threshold 0.25 RMS (calibrated)
- Wakeword interrupt during capture

ARCHITECTURE (Single-threaded, proven to work):
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ              USB MICROPHONE (hw:3,0)                     ‚îÇ
    ‚îÇ              48000 Hz / 16-bit / Mono                    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ           MAIN LOOP (Single Thread)                      ‚îÇ
    ‚îÇ  1. Read HW_CHUNK samples @ 48kHz                        ‚îÇ
    ‚îÇ  2. Resample to 512 samples @ 16kHz (scipy)              ‚îÇ
    ‚îÇ  3. Feed to Porcupine for wakeword detection             ‚îÇ
    ‚îÇ  4. On wakeword: capture until silence/timeout, transcribe‚îÇ
    ‚îÇ  5. Publish events to orchestrator via ZMQ IPC           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

NOISY ENVIRONMENT HANDLING:
    - MAX_CAPTURE_SECONDS = 15 ensures transcription even if silence not detected
    - Silence detection works in quiet environments (threshold 0.25 RMS)
    - Wakeword interrupt allows user to re-trigger if needed

IPC INTEGRATION:
    Publishes to upstream (orchestrator listens):
    - ww.detected: When wakeword is detected
    - stt.transcription: When transcription is complete
    
    Subscribes to downstream (from orchestrator):
    - cmd.listen.start: Manual trigger to start listening
    - cmd.listen.stop: Stop current capture

WAKEWORD INTERRUPT:
    During STT capture, we check for wakeword in each frame.
    If detected, we cancel current capture and restart the flow.
"""
import sys
import os
import time
import wave
import tempfile
import ctypes
import math
import argparse
import json
import signal
import threading
import numpy as np

# Suppress ALSA errors BEFORE importing PyAudio
try:
    ERROR_HANDLER_FUNC = ctypes.CFUNCTYPE(
        None, ctypes.c_char_p, ctypes.c_int,
        ctypes.c_char_p, ctypes.c_int, ctypes.c_char_p
    )
    def py_error_handler(filename, line, function, err, fmt):
        pass
    c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)
    asound = ctypes.cdll.LoadLibrary("libasound.so.2")
    asound.snd_lib_error_set_handler(c_error_handler)
except Exception:
    pass

import pyaudio
import zmq
from scipy import signal as scipy_signal
import pvporcupine

# Project imports
from pathlib import Path
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(PROJECT_ROOT))

from src.core.config_loader import load_config
from src.core.ipc import (
    TOPIC_STT,
    TOPIC_WW_DETECTED,
    TOPIC_CMD_LISTEN_START,
    TOPIC_CMD_LISTEN_STOP,
    make_publisher,
    make_subscriber,
    publish_json,
)
from src.core.logging_setup import get_logger

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CONFIGURATION (Tested and Calibrated)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

HW_RATE = 48000           # USB mic native rate
TARGET_RATE = 16000       # Porcupine/Whisper rate
SENSITIVITY = 0.7         # Wakeword sensitivity (tested: 10/10 detection)
SILENCE_THRESHOLD = 0.25  # RMS threshold (calibrated from actual mic)
SILENCE_DURATION_MS = 1200 # Stop after 1.2s of silence (was 0.8s)
MAX_CAPTURE_SECONDS = 15.0  # INCREASED: 15s max for noisy environments
MIN_CAPTURE_SECONDS = 1.5   # Give user time to speak (was 0.5s)
MIN_SPEECH_FRAMES = 3       # Must detect speech before silence can end capture


def calc_rms(samples: np.ndarray) -> float:
    """Calculate RMS amplitude (0.0 to 1.0)."""
    if len(samples) == 0:
        return 0.0
    energy = np.mean(samples.astype(np.float32) ** 2)
    return min(1.0, math.sqrt(energy) / 32768.0)


def resample_chunk(hw_samples: np.ndarray, target_len: int) -> np.ndarray:
    """Resample using scipy FFT (high quality, tested)."""
    resampled = scipy_signal.resample(hw_samples.astype(np.float32), target_len)
    return np.clip(resampled, -32768, 32767).astype(np.int16)


class VoiceService:
    """Production voice service with wakeword interrupt capability.
    
    Integrates with orchestrator via ZMQ IPC:
    - Publishes ww.detected on wakeword
    - Publishes stt.transcription after transcription
    - Listens for cmd.listen.start/stop from orchestrator
    """
    
    def __init__(self, config_path: Path):
        self.config_path = config_path
        self.raw_config = load_config(config_path) if config_path.exists() else {}
        
        # Setup logging
        logs_cfg = self.raw_config.get("logs", {}) or {}
        log_dir = Path(logs_cfg.get("directory", "logs"))
        self.logger = get_logger("voice_service", log_dir)
        
        # Get wakeword config
        ww_cfg = self.raw_config.get("wakeword", {}) or {}
        self.access_key = ww_cfg.get("access_key") or os.environ.get("PV_ACCESS_KEY", "")
        self.model_path = ww_cfg.get("model", "")
        
        # Get STT config for timeout override
        stt_cfg = self.raw_config.get("stt", {}) or {}
        self.stt_engine = str(stt_cfg.get("engine", "faster_whisper")).lower()
        self.max_capture_seconds = float(stt_cfg.get("max_capture_seconds", MAX_CAPTURE_SECONDS))
        self.silence_threshold = float(stt_cfg.get("silence_threshold", SILENCE_THRESHOLD))
        self.silence_duration_ms = int(stt_cfg.get("silence_duration_ms", SILENCE_DURATION_MS))
        azure_cfg = (stt_cfg.get("engines") or {}).get("azure_speech", {}) or {}
        self.azure_speech_key = azure_cfg.get("key") or os.environ.get("AZURE_SPEECH_KEY", "")
        self.azure_speech_region = azure_cfg.get("region") or os.environ.get("AZURE_SPEECH_REGION", "")
        self.azure_speech_endpoint = azure_cfg.get("endpoint") or os.environ.get("AZURE_SPEECH_ENDPOINT")
        self.azure_speech_language = azure_cfg.get("language") or stt_cfg.get("language", "en-US")
        self.azure_speechsdk = None
        
        # Components (initialized in start())
        self.porcupine = None
        self.stt_model = None
        self.pa = None
        self.stream = None
        self.pub = None
        self.sub = None
        
        # Frame sizes
        self.frame_length = 512  # Porcupine frame
        self.hw_chunk = int(self.frame_length * HW_RATE / TARGET_RATE)  # 1536
        
        # Statistics
        self.stats = {
            "wakeword_detections": 0,
            "stt_transcriptions": 0,
            "stt_interrupts": 0,
            "manual_triggers": 0,
        }
        
        # Control
        self._running = False
        self._manual_trigger = False
        self._stop_capture = False
        
        # Signal handling
        signal.signal(signal.SIGTERM, self._handle_signal)
        signal.signal(signal.SIGINT, self._handle_signal)
    
    def _handle_signal(self, signum, frame):
        """Handle shutdown signals gracefully."""
        self.logger.info("Received signal %s, shutting down...", signum)
        self._running = False
    
    def start(self) -> bool:
        """Initialize all components."""
        print("=== VOICE SERVICE STARTING ===", flush=True)
        self.logger.info("Voice service starting")
        print(f"Resampling: {HW_RATE}Hz ‚Üí {TARGET_RATE}Hz (scipy)", flush=True)
        print(f"Wakeword sensitivity: {SENSITIVITY}", flush=True)
        print(f"Silence threshold: {self.silence_threshold}", flush=True)
        print(f"Max capture: {self.max_capture_seconds}s (for noisy env)", flush=True)
        print("", flush=True)
        
        # Initialize Porcupine
        print("Initializing Porcupine...", flush=True)
        if not self.access_key:
            print("ERROR: Porcupine access key not set!", flush=True)
            self.logger.error("Porcupine access key not configured")
            return False
        
        try:
            self.porcupine = pvporcupine.create(
                access_key=self.access_key,
                keyword_paths=[self.model_path],
                sensitivities=[SENSITIVITY],
            )
            self.frame_length = self.porcupine.frame_length
            self.hw_chunk = int(self.frame_length * HW_RATE / TARGET_RATE)
            print(f"Porcupine ready (frame_length={self.frame_length})", flush=True)
            self.logger.info("Porcupine initialized (frame_length=%d)", self.frame_length)
        except Exception as e:
            print(f"ERROR: Porcupine init failed: {e}", flush=True)
            self.logger.error("Porcupine init failed: %s", e)
            return False
        
        # Initialize STT backend
        if self.stt_engine in {"azure_speech", "azure", "azure_stt"}:
            print("Using Azure Speech STT", flush=True)
            if not self.azure_speech_key or not self.azure_speech_region:
                print("ERROR: Azure Speech key/region not configured!", flush=True)
                self.logger.error("Azure Speech key/region not configured")
                return False
            try:
                self.azure_speechsdk = self._import_speech_sdk()
                print("Azure Speech SDK ready!", flush=True)
                self.logger.info("Azure Speech STT ready (region=%s)", self.azure_speech_region)
            except Exception as e:
                print(f"ERROR: Azure Speech SDK load failed: {e}", flush=True)
                self.logger.error("Azure Speech SDK load failed: %s", e)
                return False
        else:
            print("Loading faster-whisper model (tiny.en)...", flush=True)
            try:
                from faster_whisper import WhisperModel
                self.stt_model = WhisperModel(
                    "tiny.en",
                    device="cpu",
                    compute_type="int8",
                    cpu_threads=4,  # Use all 4 cores on Pi4
                    download_root=str(PROJECT_ROOT / "third_party/whisper-fast"),
                )
                print("STT model ready!", flush=True)
                self.logger.info("faster-whisper model loaded")
            except Exception as e:
                print(f"ERROR: STT model load failed: {e}", flush=True)
                self.logger.error("STT model load failed: %s", e)
                return False
        
        # Initialize PyAudio
        self.pa = pyaudio.PyAudio()
        
        # Find USB device
        found_device = None
        for i in range(self.pa.get_device_count()):
            info = self.pa.get_device_info_by_index(i)
            if info["maxInputChannels"] > 0 and "USB" in info["name"]:
                found_device = i
                print(f"Found USB device at index {i}: {info['name']}", flush=True)
                self.logger.info("USB audio device: %s (index %d)", info['name'], i)
                break
        
        if found_device is None:
            print("ERROR: No USB input device found!", flush=True)
            self.logger.error("No USB input device found")
            return False
        
        # Open stream
        try:
            self.stream = self.pa.open(
                rate=HW_RATE,
                channels=1,
                format=pyaudio.paInt16,
                input=True,
                input_device_index=found_device,
                frames_per_buffer=self.hw_chunk,
            )
            print(f"Audio stream ready (device {found_device})", flush=True)
        except Exception as e:
            print(f"ERROR: Failed to open audio stream: {e}", flush=True)
            self.logger.error("Failed to open audio stream: %s", e)
            return False
        
        # Initialize ZMQ publisher (upstream - events to orchestrator)
        try:
            self.pub = make_publisher(self.raw_config, channel="upstream")
            print("ZMQ publisher ready (upstream)", flush=True)
            self.logger.info("ZMQ publisher connected to upstream")
        except Exception as e:
            print(f"Warning: ZMQ publisher failed: {e}", flush=True)
            self.logger.warning("ZMQ publisher failed: %s", e)
            self.pub = None
        
        # Initialize ZMQ subscriber (downstream - commands from orchestrator)
        try:
            self.sub = make_subscriber(self.raw_config, channel="downstream")
            # Subscribe to listen commands
            self.sub.setsockopt_string(zmq.SUBSCRIBE, TOPIC_CMD_LISTEN_START.decode())
            self.sub.setsockopt_string(zmq.SUBSCRIBE, TOPIC_CMD_LISTEN_STOP.decode())
            self.sub.setsockopt(zmq.RCVTIMEO, 0)  # Non-blocking
            print("ZMQ subscriber ready (downstream)", flush=True)
            self.logger.info("ZMQ subscriber connected to downstream")
        except Exception as e:
            print(f"Warning: ZMQ subscriber failed: {e}", flush=True)
            self.logger.warning("ZMQ subscriber failed: %s", e)
            self.sub = None
        
        print("", flush=True)
        print("=" * 50, flush=True)
        print("üé§ Voice service ready!", flush=True)
        print("   Say 'HEY ROBO' to trigger", flush=True)
        print("   Say 'HEY ROBO' during capture to interrupt!", flush=True)
        print(f"   Max capture: {self.max_capture_seconds}s (noisy env safe)", flush=True)
        print("=" * 50, flush=True)
        print("", flush=True)
        
        self._running = True
        self.logger.info("Voice service started successfully")
        return True
    
    def stop(self):
        """Clean up resources."""
        self._running = False
        self.logger.info("Voice service stopping...")
        
        if self.stream:
            try:
                self.stream.stop_stream()
                self.stream.close()
            except:
                pass
        
        if self.pa:
            try:
                self.pa.terminate()
            except:
                pass
        
        if self.porcupine:
            try:
                self.porcupine.delete()
            except:
                pass
        
        if self.sub:
            try:
                self.sub.close()
            except:
                pass
        
        if self.pub:
            try:
                self.pub.close()
            except:
                pass
        
        self.logger.info("Voice service stopped. Stats: %s", self.stats)
        print(f"Voice service stopped. Stats: {self.stats}", flush=True)
    
    def _read_and_resample(self) -> np.ndarray:
        """Read one chunk from mic and resample to 16kHz."""
        data = self.stream.read(self.hw_chunk, exception_on_overflow=False)
        hw_samples = np.frombuffer(data, dtype=np.int16)
        return resample_chunk(hw_samples, self.frame_length)
    
    def _check_wakeword(self, samples: np.ndarray) -> bool:
        """Check if wakeword is in samples. Returns True if detected."""
        result = self.porcupine.process(samples.tolist())
        return result >= 0
    
    def _publish_wakeword(self):
        """Publish wakeword detection event."""
        if self.pub:
            try:
                payload = {
                    "timestamp": int(time.time()),
                    "keyword": "hey robo",
                    "confidence": 0.99,
                    "source": "voice_service",
                }
                publish_json(self.pub, TOPIC_WW_DETECTED, payload)
            except:
                pass
    
    def _publish_stt(self, text: str, confidence: float, capture_ms: int, whisper_ms: int):
        """Publish STT result."""
        if self.pub:
            try:
                payload = {
                    "timestamp": int(time.time()),
                    "text": text.strip(),
                    "confidence": float(confidence),
                    "language": "en",
                    "durations_ms": {
                        "capture": capture_ms,
                        "whisper": whisper_ms,
                        "total": capture_ms + whisper_ms,
                    },
                    "kind": "final",
                }
                publish_json(self.pub, TOPIC_STT, payload)
            except:
                pass

    @staticmethod
    def _import_speech_sdk():
        try:
            import azure.cognitiveservices.speech as speechsdk  # type: ignore
        except Exception as exc:  # pragma: no cover
            raise RuntimeError(
                "azure-cognitiveservices-speech is required for Azure STT; install in stt venv"
            ) from exc
        return speechsdk

    @staticmethod
    def _extract_azure_confidence(speechsdk, result) -> float:
        try:
            json_blob = result.properties.get(speechsdk.PropertyId.SpeechServiceResponse_JsonResult)
            if not json_blob:
                return 0.0
            data = json.loads(json_blob)
            nbest = data.get("NBest") or data.get("nbest")
            if isinstance(nbest, list) and nbest:
                conf = nbest[0].get("Confidence") or nbest[0].get("confidence")
                if conf is not None:
                    return max(0.0, min(1.0, float(conf)))
        except Exception:
            return 0.0
        return 0.0

    def _transcribe_azure(self, audio: np.ndarray) -> tuple:
        if not self.azure_speechsdk:
            return "", 0.0, 0

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            wav_path = f.name

        try:
            with wave.open(wav_path, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(TARGET_RATE)
                wf.writeframes(audio.tobytes())

            speech_config = self.azure_speechsdk.SpeechConfig(
                subscription=self.azure_speech_key,
                region=self.azure_speech_region,
            )
            if self.azure_speech_endpoint:
                speech_config.endpoint = self.azure_speech_endpoint
            speech_config.speech_recognition_language = self.azure_speech_language

            audio_config = self.azure_speechsdk.audio.AudioConfig(filename=wav_path)
            recognizer = self.azure_speechsdk.SpeechRecognizer(
                speech_config=speech_config,
                audio_config=audio_config,
            )

            start = time.time()
            result = recognizer.recognize_once_async().get()
            azure_ms = int((time.time() - start) * 1000)

            if result.reason == self.azure_speechsdk.ResultReason.RecognizedSpeech:
                text = (result.text or "").strip()
                confidence = self._extract_azure_confidence(self.azure_speechsdk, result) or 0.9
                return text, confidence, azure_ms

            if result.reason == self.azure_speechsdk.ResultReason.NoMatch:
                self.logger.debug("Azure STT no match")
            elif result.reason == self.azure_speechsdk.ResultReason.Canceled:
                details = result.cancellation_details
                self.logger.error("Azure STT canceled: %s", details.reason)
                if details.error_details:
                    self.logger.error("Azure STT error: %s", details.error_details)
            else:
                self.logger.warning("Azure STT unexpected result: %s", result.reason)
            return "", 0.0, azure_ms
        finally:
            try:
                os.unlink(wav_path)
            except Exception:
                pass
    
    def _transcribe(self, audio: np.ndarray) -> tuple:
        """Transcribe audio using configured STT engine."""
        if self.stt_engine in {"azure_speech", "azure", "azure_stt"}:
            return self._transcribe_azure(audio)
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            wav_path = f.name
        
        try:
            with wave.open(wav_path, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(TARGET_RATE)
                wf.writeframes(audio.tobytes())
            
            start = time.time()
            segments, info = self.stt_model.transcribe(
                wav_path,
                language="en",
                beam_size=1,
                vad_filter=True,
            )
            
            text_parts = []
            logprobs = []
            for seg in segments:
                text_parts.append(seg.text.strip() if seg.text else "")
                if seg.avg_logprob is not None:
                    logprobs.append(seg.avg_logprob)
            
            text = " ".join(p for p in text_parts if p)
            
            if logprobs:
                confidence = max(0.0, min(1.0, math.exp(sum(logprobs) / len(logprobs))))
            else:
                confidence = 0.8 if text else 0.0
            
            whisper_ms = int((time.time() - start) * 1000)
            return text, confidence, whisper_ms
        
        finally:
            try:
                os.unlink(wav_path)
            except:
                pass
    
    def run(self):
        """Main event loop - Orchestrator-driven flow.
        
        Flow:
        1. IDLE: Wait for wakeword
        2. On wakeword: publish ww.detected, wait for cmd.listen.start
        3. CAPTURING: Record until silence/timeout, check for wakeword interrupt
        4. TRANSCRIBING: Run STT, publish stt.transcription
        5. Return to IDLE
        """
        chunk_ms = self.frame_length / TARGET_RATE * 1000
        silence_frames_needed = int(self.silence_duration_ms / chunk_ms)
        
        while self._running:
            try:
                # PHASE 1: Wait for wakeword
                print("[IDLE] Listening for wakeword...", flush=True)
                self.logger.info("IDLE: Waiting for wakeword")
                self._manual_trigger = False
                self._stop_capture = False
                
                wakeword_detected = False
                while self._running and not wakeword_detected:
                    # Check for manual trigger from orchestrator
                    self._check_commands()
                    if self._manual_trigger:
                        self._manual_trigger = False
                        self.stats["manual_triggers"] += 1
                        print("", flush=True)
                        print(f"üéØ MANUAL TRIGGER #{self.stats['manual_triggers']}!", flush=True)
                        self.logger.info("Manual trigger from orchestrator")
                        # Go directly to capture (no need to wait for cmd.listen.start)
                        wakeword_detected = True
                        break
                    
                    samples = self._read_and_resample()
                    
                    if self._check_wakeword(samples):
                        self.stats["wakeword_detections"] += 1
                        print("", flush=True)
                        print(f"üéØ WAKEWORD #{self.stats['wakeword_detections']}!", flush=True)
                        self.logger.info("Wakeword detected (#%d)", self.stats['wakeword_detections'])
                        self._publish_wakeword()
                        
                        # WAIT for orchestrator to send cmd.listen.start
                        print("[WAITING] For orchestrator to start listening...", flush=True)
                        self.logger.info("Waiting for cmd.listen.start from orchestrator")
                        wait_start = time.time()
                        wait_timeout = 2.0  # Max 2 seconds to wait
                        
                        while self._running and (time.time() - wait_start) < wait_timeout:
                            self._check_commands()
                            if self._manual_trigger:
                                self._manual_trigger = False
                                wakeword_detected = True
                                self.logger.info("Received cmd.listen.start")
                                break
                            # Keep reading mic to prevent buffer overflow
                            _ = self._read_and_resample()
                        
                        if not wakeword_detected:
                            self.logger.warning("Timeout waiting for cmd.listen.start")
                            # Continue to capture anyway (fallback)
                            wakeword_detected = True
                        break
                
                if not self._running:
                    break
                
                # PHASE 2: Capture audio until silence OR timeout (with wakeword interrupt)
                print("[CAPTURING] Speak now (pause when done)...", flush=True)
                self.logger.info("CAPTURING: Recording user speech")
                
                capture_buffer = []
                capture_start = time.time()
                silence_frames = 0
                speech_frames = 0  # Track frames with speech detected
                interrupted = False
                self._stop_capture = False
                
                while self._running and not self._stop_capture:
                    # Check for stop command
                    self._check_commands()
                    if self._stop_capture:
                        print("   (Capture stopped by command)", flush=True)
                        self.logger.info("Capture stopped by command")
                        break
                    
                    samples = self._read_and_resample()
                    
                    # CHECK FOR WAKEWORD INTERRUPT
                    if self._check_wakeword(samples):
                        self.stats["stt_interrupts"] += 1
                        self.stats["wakeword_detections"] += 1
                        print("", flush=True)
                        print(f"‚ö†Ô∏è INTERRUPT! Wakeword during capture - restarting!", flush=True)
                        self.logger.info("Wakeword interrupt during capture")
                        self._publish_wakeword()
                        interrupted = True
                        break
                    
                    capture_buffer.append(samples)
                    elapsed = time.time() - capture_start
                    
                    # Check max duration (IMPORTANT for noisy environments)
                    if elapsed >= self.max_capture_seconds:
                        print(f"   (Max {self.max_capture_seconds}s reached - noisy env auto-stop)", flush=True)
                        self.logger.info("Max capture duration reached (%.1fs)", self.max_capture_seconds)
                        break
                    
                    # Silence/Speech detection
                    rms = calc_rms(samples)
                    if rms < self.silence_threshold:
                        silence_frames += 1
                        # Only allow silence to end capture if:
                        # 1. Enough silence frames accumulated
                        # 2. Minimum capture time elapsed  
                        # 3. SPEECH WAS DETECTED (prevents premature stop)
                        if (silence_frames >= silence_frames_needed and 
                            elapsed >= MIN_CAPTURE_SECONDS and
                            speech_frames >= MIN_SPEECH_FRAMES):
                            print(f"   (Silence after {elapsed:.1f}s, {speech_frames} speech frames)", flush=True)
                            self.logger.info("Silence detected after %.1fs (speech_frames=%d)", elapsed, speech_frames)
                            break
                    else:
                        silence_frames = 0
                        speech_frames += 1  # Count frames with audio above threshold
                
                # If interrupted or stopped, skip transcription and restart
                if interrupted or self._stop_capture:
                    continue
                
                if not self._running or not capture_buffer:
                    continue
                
                # PHASE 3: Transcribe
                capture_ms = int((time.time() - capture_start) * 1000)
                audio = np.concatenate(capture_buffer)
                audio_duration = len(audio) / TARGET_RATE
                
                print(f"[TRANSCRIBING] {audio_duration:.1f}s of audio...", flush=True)
                self.logger.info("TRANSCRIBING: %.1fs of audio", audio_duration)
                
                text, confidence, whisper_ms = self._transcribe(audio)
                self.stats["stt_transcriptions"] += 1
                
                print("", flush=True)
                print(f"üìù \"{text}\"", flush=True)
                print(f"   conf={confidence:.2f}, capture={capture_ms}ms, whisper={whisper_ms}ms", flush=True)
                print("", flush=True)
                
                self.logger.info(
                    "STT result: '%s' (conf=%.2f, capture=%dms, whisper=%dms)",
                    text[:50] if text else "", confidence, capture_ms, whisper_ms
                )
                
                self._publish_stt(text, confidence, capture_ms, whisper_ms)
                
            except KeyboardInterrupt:
                print("\nInterrupted by user", flush=True)
                self.logger.info("Interrupted by user")
                break
            except Exception as e:
                print(f"Error in main loop: {e}", flush=True)
                self.logger.error("Error in main loop: %s", e)
                time.sleep(0.1)
    
    def _check_commands(self):
        """Check for commands from orchestrator (non-blocking)."""
        if not self.sub:
            return
        
        try:
            while True:
                try:
                    topic, data = self.sub.recv_multipart(flags=zmq.NOBLOCK)
                    payload = json.loads(data)
                    
                    if topic == TOPIC_CMD_LISTEN_START:
                        self._manual_trigger = True
                        self.logger.debug("Received cmd.listen.start")
                    elif topic == TOPIC_CMD_LISTEN_STOP:
                        self._stop_capture = True
                        self.logger.debug("Received cmd.listen.stop")
                        
                except zmq.Again:
                    break  # No more messages
        except Exception as e:
            self.logger.warning("Error checking commands: %s", e)


def main():
    parser = argparse.ArgumentParser(description="Voice Service")
    parser.add_argument("--config", default="config/system.yaml", help="Config file")
    args = parser.parse_args()
    
    config_path = PROJECT_ROOT / args.config
    
    service = VoiceService(config_path)
    
    if not service.start():
        print("Failed to start voice service!", flush=True)
        sys.exit(1)
    
    try:
        service.run()
    finally:
        service.stop()


if __name__ == "__main__":
    main()
